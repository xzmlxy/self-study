import xgboost
import sklearn
from code.BaseModel import BaseModel


class XGBModel(BaseModel):
    def __init__(self, data, y_name: str = None, params: dict = None):
        super().__init__(data, y_name, params)
        if self.params is None:
            self.params = {'learning_rate': 0.1, 'objective': 'multi:softmax', 'num_class': 4,
                           'n_estimators': 200, 'max_depth': 8, 'reg_alpha': 0, 'reg_lambda': 1, 'gamma': 0,
                           'min_child_weight': 1, 'num_parallel_tree':1}

    def _get_model(self,x_train, y_train, x_test, y_test):
        model =  xgboost.XGBRFClassifier(**self.params)
        if x_test is not None:
            model.fit(x_train, y_train, eval_metric='mlogloss', early_stopping_rounds=10, eval_set=[(x_test, y_test)])
        else:
            model.fit(x_train, y_train)
        return model
            
            
 import lightgbm as lgb
import sklearn
from code.BaseModel import BaseModel


class LightGBModel(BaseModel):
    def __init__(self, data, y_name: str = None, params: dict = None):
        super().__init__(data, y_name, params)
        if self.params is None:
            self.params = {'learning_rate': 0.1, 'objective': 'multiclass', 'num_class': 4, 'n_estimators': 100,
                           'num_leaves': 36, 'max_depth': 5, 'min_child_weight': 0.001, 'min_child_samples': 20,
                           'reg_alpha': 0.0, 'reg_lambda': 0.0, 'fold_len_multiplier': 2}

    def _get_model(self, x_train, y_train, x_test, y_test):
        model = lgb.LGBMClassifier(**self.params)
        if x_test is not None:
            model.fit(x_train, y_train, eval_metric='logloss', early_stopping_rounds=10, eval_set=[(x_test, y_test)])
        else:
            model.fit(x_train, y_train)
        return model
        
        
        
        
        import catboost
import sklearn
from code.BaseModel import BaseModel


class CatBModel(BaseModel):
    def __init__(self, data, y_name: str = None, params: dict = None):
        super().__init__(data, y_name, params)
        if self.params is None:
            self.params = {'learning_rate': 0.1, 'iterations': 100, 'depth': 6, 'od_type': 'Iter', 'classes_count': 4,
                           'loss_function': 'Logloss', 'max_leaves': 100, 'min_data_in_leaf': 10}

    def _get_model(self, x_train, y_train, x_test, y_test):
        if x_test is not None:
            self.params['early_stopping_rounds'] = 100
            model = catboost.CatBoostClassifier(**self.params)
            model.fit(x_train, y_train, eval_set=[(x_test, y_test)])
        else:
            model = catboost.CatBoostClassifier(**self.params)
            model.fit(x_train, y_train)
        return model

