
    def get_params(self, deep=False):
        params = {'alpha': self.alpha, 'num_iters': self.num_iters}
        return params

    def set_params(self, **parameters):
        for parameter, value in parameters.items(): 
            setattr(self, parameter, value)
        return self




        else:
            print('No param need grid search for this model.')
            
            
            
            
            
from code.models.DLmodels.CNN_models import CNNModel
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from code.models.model_wrapper.BaseModelWrapper import BaseModel


class DLModel(BaseModel):

    def __init__(self, y_name: str = None, params: dict = None):
        super().__init__(y_name, params)
        self.scaler = MinMaxScaler()

    def _get_model(self, x_train, y_train, x_test, y_test):
        model = CNNModel(**self.params)
        if x_test is not None:
            model.fit(x_train, y_train)
        else:
            model.fit(x_train, y_train)
        return model

    def create_adjust_params(self):
        return None

    def extra_pre_process(self, data):
        features = data.columns
        return self.scaler.fit_transform(data[features])
        
        
        
        
        
import tensorflow as tf
import numpy as np
import random


class CNNModel:
    def __init__(self, early_stop: int = 20, repeat_time: int = 30, epochs: int = 100, save_name: str = 'cnn_model.w8',
                 learning_rate: float = 0.1, batch_size: int = 10, optimizer=None, dropout: float = 0.2, reg=True,
                 activate: str = 'relu', structure_function=None):
        self.model = None
        self.early_stop = early_stop
        self.repeat_time = repeat_time
        self.epochs = epochs
        self.save_name = save_name
        self.dropout = dropout
        self.learning_rate = learning_rate
        self.activate = activate
        self.batch_size = batch_size
        self.mask = None
        self.reg = reg
        self.optimizer = optimizer
        self.structure_function = structure_function
        if self.structure_function is None:
            print('Cannot create model without structure_function!')
            raise Exception

    def fit(self, x_train, y_train, x_test, y_test):
        self.__create_feat_2d(x_train.columns)
        inp = tf.keras.layers.Input(shape=(len(x_train)))
        x = tf.keras.layers.Lambda(lambda x: tf.gather(x, self.mask, axis=1))(inp)
        x = tf.keras.layers.Reshape((self.repeat_time, len(x_train), 1))(x)
        self.model = self.structure_function(x, self.activate, self.dropout)
        if self.optimizer is None:
            self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')
        else:
            self.model.compile(optimizer=self.optimizer)
        # print(model.summary())
        save_best = tf.keras.callbacks.ModelCheckpoint(self.save_name, save_weights_only=True, save_best_only=True,
                                                       verbose=1)
        if x_test is None:
            self.model.fit(x_train, y_train, epochs=self.epochs, callbacks=[save_best])
        else:
            early_stop = tf.keras.callbacks.EarlyStopping(patience=self.early_stop)
            self.model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=self.epochs,
                           callbacks=[save_best, early_stop])
        self.model.load_weights(self.save_name)

    def __create_feat_2d(self, features):
        n_feats = len(features)
        self.mask = np.zeros((self.repeat_time, n_feats), dtype=np.int)
        for i in range(self.repeat_time):
            l = list(range(n_feats))
            for j in range(n_feats):
                c = l.pop(random.choice(range(len(l))))
                self.mask[i, j] = c
        self.mask = tf.convert_to_tensor(self.mask)

    def predict(self, x_test):
        if self.model is not None:
            if self.reg:
                result = self.model.predict(x_test)
            else:
                result = self.model.predict_classes(x_test)
            return result
            
            
  
  from code.models.DLmodels.CNN_models import CNNModel
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from code.models.model_wrapper.BaseModelWrapper import BaseModel


class DLModel(BaseModel):

    def __init__(self, y_name: str = None, params: dict = None):
        super().__init__(y_name, params)
        self.scaler = MinMaxScaler()

    def _get_model(self, x_train, y_train, x_test, y_test):
        model = CNNModel(**self.params)
        if x_test is not None:
            model.fit(x_train, y_train)
        else:
            model.fit(x_train, y_train)
        return model

    def create_adjust_params(self):
        return None

    def extra_pre_process(self, data):
        features = data.columns
        return self.scaler.fit_transform(data[features])
        
        
   
  import tensorflow as tf


def model_for_cnn_1(input_data, activate: str = 'relu', drop: float = 0.2):
    x = tf.keras.layers.Conv2D(18, (50, 50), strides=50, activation='relu')(input_data)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(100, activation=activate)(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dropout(drop)(x)
    x = tf.keras.layers.Dense(50, activation=activate)(x)
    x = tf.keras.layers.LayerNormalization()(x)
    x = tf.keras.layers.Dropout(drop)(x)
    return tf.keras.layers.Dense(1)(x)
