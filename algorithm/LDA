基础数学知识：
（1）分布：二项分布、多项分布是指，在某事件结果的概率分布已知的情况下，多次重复该事件，得到的统计结果将会服从的概率分布。
          而Beta分布和Dirichlet分布是指，重复某事件并获取事件结果的统计，进而估计得到的该事件结果的概率分布的概率分布。所以，可以从Beta分布和Dirichlet分布中抽样获取到事件结果的概率分布。

按照以下方式生成文档（模型原理）：
（1）存在两个Dirichlet分布，一个是关于Doc-Topic的，记为Dirichlet1；另一个是关于Topic-Word的，记为Dirichlet2。
（2）首先从Dirichlet2从抽样K次，得到K个Topic-Word多项分布。
（3）从Dirichlet1中抽样生成一篇文档的Doc-Topic多项分布，根据该分布抽样生成当前词的主题，记为T。然后根据主题T的Topic-Word多项分布，抽样生成具体的词。循环该过程，直至生成所有文档。

训练原理：
（1）使用吉布斯采样，获取Doc-Topic和Topic-Word的频率共现矩阵，进而得到两个Dirichlet分布的参数。
（2）根据吉布斯采样的要求，必须有完整的条件概率。具体推导过程不表，推导得到的条件概率的通俗解释如下：文章D中，词W为主题T的条件概率等于=词W在主题T中的比重*主题T在文章D中的比重。
（3）当所有词的主题趋于收敛时（一般不判断是否已完全收敛，而是通过足够多的训练步数，来达到收敛状态的要求），训练完成，统计相应数据即可。

LDA的使用：
（1）训练好的LDA模型，主要用于推断新文档的主题，以及获取新的Topic-Word多项分布。所以训练得到的关于Doc-Topic的内容（包括对应的Dirichlet分布和频率共现矩阵）一般不需要保留。
（2）因为需要在不更换Topic的情况下，推断新文档的主题，所以训练得到的Topic-Word频率共现矩阵是需要保留的。
（3）因为可能需要尝试新的主题，所以关于Topic-Word的Dirichlet分布的参数也需要保留。
